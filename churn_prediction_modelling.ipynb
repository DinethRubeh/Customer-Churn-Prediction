{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling data\n",
    "\n",
    "Lets select the best model among logistic regression, svm, random forest, gbm & neural network.\n",
    "\n",
    "Will be using 5 fold cross validation in the model training process and Grid search for the model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load feature engineered train, test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('data/train_features.csv')\n",
    "x_test = pd.read_csv('data/test_features.csv')\n",
    "\n",
    "y_train = pd.read_csv('data/train_labels.csv')\n",
    "y_test = pd.read_csv('data/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to evaluate cross validation results\n",
    "def print_results(results):\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('Acc: {} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))\n",
    "        \n",
    "    print('\\nBest Params: {},'.format(results.best_params_), 'Accuracy: {}'.format(results.best_score_))\n",
    "        \n",
    "# Method to get f1 score of the best model\n",
    "def best_model_f1_score(results):\n",
    "    y_pred = results.best_estimator_.predict(x_test)\n",
    "    # return f1 score\n",
    "    return f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.717 (+/-0.12) for {'C': 0.001}\n",
      "Acc: 0.731 (+/-0.11) for {'C': 0.01}\n",
      "Acc: 0.748 (+/-0.106) for {'C': 0.1}\n",
      "Acc: 0.752 (+/-0.097) for {'C': 1}\n",
      "Acc: 0.752 (+/-0.096) for {'C': 10}\n",
      "Acc: 0.752 (+/-0.097) for {'C': 100}\n",
      "Acc: 0.752 (+/-0.097) for {'C': 1000}\n",
      "\n",
      "Best Params: {'C': 10}, Accuracy: 0.752422480620155\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "parameters = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "lr_cv = GridSearchCV(lr, parameters, cv=5)\n",
    "lr_cv.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# Find best best model\n",
    "print_results(lr_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### F1 score gives an idea about both precision and recall. it is a better metric when there are imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.45484581497797355\n"
     ]
    }
   ],
   "source": [
    "print(\"lr:\", best_model_f1_score(lr_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.749 (+/-0.103) for {'C': 0.1, 'kernel': 'linear'}\n",
      "Acc: 0.77 (+/-0.124) for {'C': 0.1, 'kernel': 'rbf'}\n",
      "Acc: 0.751 (+/-0.098) for {'C': 1, 'kernel': 'linear'}\n",
      "Acc: 0.807 (+/-0.1) for {'C': 1, 'kernel': 'rbf'}\n",
      "Acc: 0.752 (+/-0.098) for {'C': 10, 'kernel': 'linear'}\n",
      "Acc: 0.822 (+/-0.086) for {'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Best Params: {'C': 10, 'kernel': 'rbf'}, Accuracy: 0.8220930232558139\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "parameters = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "svm_cv = GridSearchCV(svc, parameters, cv=5)\n",
    "svm_cv.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "print_results(svm_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm: 0.5703794369645043\n"
     ]
    }
   ],
   "source": [
    "print(\"svm:\", best_model_f1_score(svm_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.742 (+/-0.059) for {'max_depth': 2, 'n_estimators': 5}\n",
      "Acc: 0.772 (+/-0.096) for {'max_depth': 2, 'n_estimators': 50}\n",
      "Acc: 0.761 (+/-0.1) for {'max_depth': 2, 'n_estimators': 250}\n",
      "Acc: 0.778 (+/-0.076) for {'max_depth': 4, 'n_estimators': 5}\n",
      "Acc: 0.795 (+/-0.084) for {'max_depth': 4, 'n_estimators': 50}\n",
      "Acc: 0.798 (+/-0.096) for {'max_depth': 4, 'n_estimators': 250}\n",
      "Acc: 0.815 (+/-0.076) for {'max_depth': 8, 'n_estimators': 5}\n",
      "Acc: 0.825 (+/-0.075) for {'max_depth': 8, 'n_estimators': 50}\n",
      "Acc: 0.825 (+/-0.071) for {'max_depth': 8, 'n_estimators': 250}\n",
      "Acc: 0.82 (+/-0.066) for {'max_depth': 16, 'n_estimators': 5}\n",
      "Acc: 0.846 (+/-0.08) for {'max_depth': 16, 'n_estimators': 50}\n",
      "Acc: 0.848 (+/-0.083) for {'max_depth': 16, 'n_estimators': 250}\n",
      "Acc: 0.818 (+/-0.076) for {'max_depth': 32, 'n_estimators': 5}\n",
      "Acc: 0.848 (+/-0.08) for {'max_depth': 32, 'n_estimators': 50}\n",
      "Acc: 0.85 (+/-0.076) for {'max_depth': 32, 'n_estimators': 250}\n",
      "Acc: 0.823 (+/-0.068) for {'max_depth': None, 'n_estimators': 5}\n",
      "Acc: 0.847 (+/-0.08) for {'max_depth': None, 'n_estimators': 50}\n",
      "Acc: 0.851 (+/-0.076) for {'max_depth': None, 'n_estimators': 250}\n",
      "\n",
      "Best Params: {'max_depth': None, 'n_estimators': 250}, Accuracy: 0.8505813953488373\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250],\n",
    "    'max_depth': [2, 4, 8, 16, 32, None]\n",
    "}\n",
    "\n",
    "rf_cv = GridSearchCV(rf, parameters, cv=5)\n",
    "rf_cv.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "print_results(rf_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf: 0.5778069599474721\n"
     ]
    }
   ],
   "source": [
    "print(\"rf:\", best_model_f1_score(rf_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The default value for max_depth is None, which means that each tree will expand until every leaf is pure. A pure leaf is one where all of the data on the leaf comes from the same class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.68 (+/-0.094) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 5}\n",
      "Acc: 0.705 (+/-0.04) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 50}\n",
      "Acc: 0.748 (+/-0.076) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 250}\n",
      "Acc: 0.775 (+/-0.077) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 500}\n",
      "Acc: 0.748 (+/-0.087) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 5}\n",
      "Acc: 0.754 (+/-0.087) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "Acc: 0.807 (+/-0.061) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 250}\n",
      "Acc: 0.819 (+/-0.064) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "Acc: 0.777 (+/-0.075) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 5}\n",
      "Acc: 0.79 (+/-0.061) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50}\n",
      "Acc: 0.821 (+/-0.069) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 250}\n",
      "Acc: 0.831 (+/-0.071) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500}\n",
      "Acc: 0.803 (+/-0.072) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 5}\n",
      "Acc: 0.812 (+/-0.077) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50}\n",
      "Acc: 0.831 (+/-0.07) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 250}\n",
      "Acc: 0.845 (+/-0.076) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 500}\n",
      "Acc: 0.803 (+/-0.068) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 5}\n",
      "Acc: 0.817 (+/-0.07) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 50}\n",
      "Acc: 0.838 (+/-0.075) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 250}\n",
      "Acc: 0.854 (+/-0.076) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 500}\n",
      "Acc: 0.69 (+/-0.102) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 5}\n",
      "Acc: 0.778 (+/-0.078) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 50}\n",
      "Acc: 0.811 (+/-0.071) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 250}\n",
      "Acc: 0.814 (+/-0.07) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 500}\n",
      "Acc: 0.757 (+/-0.089) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 5}\n",
      "Acc: 0.819 (+/-0.066) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "Acc: 0.839 (+/-0.071) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 250}\n",
      "Acc: 0.841 (+/-0.066) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "Acc: 0.793 (+/-0.058) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 5}\n",
      "Acc: 0.833 (+/-0.068) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}\n",
      "Acc: 0.854 (+/-0.077) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 250}\n",
      "Acc: 0.862 (+/-0.073) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500}\n",
      "Acc: 0.81 (+/-0.078) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 5}\n",
      "Acc: 0.844 (+/-0.07) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50}\n",
      "Acc: 0.865 (+/-0.079) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 250}\n",
      "Acc: 0.869 (+/-0.073) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Acc: 0.812 (+/-0.075) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 5}\n",
      "Acc: 0.853 (+/-0.076) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 50}\n",
      "Acc: 0.869 (+/-0.076) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 250}\n",
      "Acc: 0.873 (+/-0.065) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 500}\n",
      "Acc: 0.773 (+/-0.067) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 5}\n",
      "Acc: 0.814 (+/-0.069) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 50}\n",
      "Acc: 0.815 (+/-0.076) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 250}\n",
      "Acc: 0.814 (+/-0.078) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 500}\n",
      "Acc: 0.808 (+/-0.07) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 5}\n",
      "Acc: 0.822 (+/-0.068) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 50}\n",
      "Acc: 0.825 (+/-0.062) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 250}\n",
      "Acc: 0.829 (+/-0.068) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 500}\n",
      "Acc: 0.817 (+/-0.07) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 5}\n",
      "Acc: 0.832 (+/-0.064) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 50}\n",
      "Acc: 0.845 (+/-0.064) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 250}\n",
      "Acc: 0.852 (+/-0.062) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 500}\n",
      "Acc: 0.821 (+/-0.065) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 5}\n",
      "Acc: 0.84 (+/-0.069) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 50}\n",
      "Acc: 0.863 (+/-0.064) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 250}\n",
      "Acc: 0.869 (+/-0.068) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Acc: 0.817 (+/-0.076) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 5}\n",
      "Acc: 0.849 (+/-0.077) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 50}\n",
      "Acc: 0.874 (+/-0.063) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 250}\n",
      "Acc: 0.866 (+/-0.082) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 500}\n",
      "\n",
      "Best Params: {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 250}, Accuracy: 0.8743217054263566\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250, 500],\n",
    "    'max_depth': [1, 3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "gbm_cv = GridSearchCV(gb, parameters, cv=5)\n",
    "gbm_cv.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "print_results(gbm_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm: 0.5683060109289618\n"
     ]
    }
   ],
   "source": [
    "print(\"gbm:\", best_model_f1_score(gbm_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 1024)              11264     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 292,225\n",
      "Trainable params: 292,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "ann_model = Sequential()\n",
    "\n",
    "ann_model.add(Dense(1024, input_dim = 10, activation = 'relu'))\n",
    "ann_model.add(Dropout(0.4))\n",
    "\n",
    "ann_model.add(Dense(256, activation = 'relu'))\n",
    "ann_model.add(Dropout(0.4))\n",
    "\n",
    "ann_model.add(Dense(64, activation = 'relu'))\n",
    "ann_model.add(Dropout(0.4))\n",
    "\n",
    "ann_model.add(Dense(32, activation = 'relu'))\n",
    "\n",
    "ann_model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "ann_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "ann_model.compile(loss='mse', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10320 samples, validate on 3500 samples\n",
      "Epoch 1/25\n",
      "10320/10320 [==============================] - 5s 519us/step - loss: 0.1810 - accuracy: 0.7274 - val_loss: 0.1789 - val_accuracy: 0.7397\n",
      "Epoch 2/25\n",
      "10320/10320 [==============================] - 6s 613us/step - loss: 0.1585 - accuracy: 0.7699 - val_loss: 0.1650 - val_accuracy: 0.7517\n",
      "Epoch 3/25\n",
      "10320/10320 [==============================] - 6s 542us/step - loss: 0.1507 - accuracy: 0.7812 - val_loss: 0.1664 - val_accuracy: 0.7566\n",
      "Epoch 4/25\n",
      "10320/10320 [==============================] - 6s 555us/step - loss: 0.1439 - accuracy: 0.7948 - val_loss: 0.1341 - val_accuracy: 0.8106\n",
      "Epoch 5/25\n",
      "10320/10320 [==============================] - 6s 611us/step - loss: 0.1403 - accuracy: 0.7990 - val_loss: 0.1414 - val_accuracy: 0.7994\n",
      "Epoch 6/25\n",
      "10320/10320 [==============================] - 6s 614us/step - loss: 0.1368 - accuracy: 0.8040 - val_loss: 0.1751 - val_accuracy: 0.7357\n",
      "Epoch 7/25\n",
      "10320/10320 [==============================] - 8s 794us/step - loss: 0.1349 - accuracy: 0.8086 - val_loss: 0.1431 - val_accuracy: 0.7974\n",
      "Epoch 8/25\n",
      "10320/10320 [==============================] - 7s 675us/step - loss: 0.1337 - accuracy: 0.8080 - val_loss: 0.1322 - val_accuracy: 0.8177\n",
      "Epoch 9/25\n",
      "10320/10320 [==============================] - 6s 567us/step - loss: 0.1305 - accuracy: 0.8192 - val_loss: 0.1339 - val_accuracy: 0.8117\n",
      "Epoch 10/25\n",
      "10320/10320 [==============================] - 9s 891us/step - loss: 0.1296 - accuracy: 0.8179 - val_loss: 0.1514 - val_accuracy: 0.7871\n",
      "Epoch 11/25\n",
      "10320/10320 [==============================] - 7s 713us/step - loss: 0.1290 - accuracy: 0.8224 - val_loss: 0.1325 - val_accuracy: 0.8094\n",
      "Epoch 12/25\n",
      "10320/10320 [==============================] - 6s 573us/step - loss: 0.1290 - accuracy: 0.8184 - val_loss: 0.1348 - val_accuracy: 0.8109\n",
      "Epoch 13/25\n",
      "10320/10320 [==============================] - 6s 560us/step - loss: 0.1281 - accuracy: 0.8207 - val_loss: 0.1447 - val_accuracy: 0.7871\n",
      "Epoch 14/25\n",
      "10320/10320 [==============================] - 7s 683us/step - loss: 0.1257 - accuracy: 0.8241 - val_loss: 0.1415 - val_accuracy: 0.8009\n",
      "Epoch 15/25\n",
      "10320/10320 [==============================] - 6s 588us/step - loss: 0.1270 - accuracy: 0.8223 - val_loss: 0.1417 - val_accuracy: 0.7960\n",
      "Epoch 16/25\n",
      "10320/10320 [==============================] - 6s 602us/step - loss: 0.1246 - accuracy: 0.8249 - val_loss: 0.1388 - val_accuracy: 0.8069TA: 0s - l\n",
      "Epoch 17/25\n",
      "10320/10320 [==============================] - 8s 788us/step - loss: 0.1248 - accuracy: 0.8253 - val_loss: 0.1323 - val_accuracy: 0.8137\n",
      "Epoch 18/25\n",
      "10320/10320 [==============================] - 8s 799us/step - loss: 0.1251 - accuracy: 0.8214 - val_loss: 0.1525 - val_accuracy: 0.7803\n",
      "Epoch 19/25\n",
      "10320/10320 [==============================] - 8s 823us/step - loss: 0.1238 - accuracy: 0.8292 - val_loss: 0.1352 - val_accuracy: 0.8046\n",
      "Epoch 20/25\n",
      "10320/10320 [==============================] - 8s 755us/step - loss: 0.1242 - accuracy: 0.8296 - val_loss: 0.1638 - val_accuracy: 0.7640\n",
      "Epoch 21/25\n",
      "10320/10320 [==============================] - 10s 970us/step - loss: 0.1232 - accuracy: 0.8297 - val_loss: 0.1345 - val_accuracy: 0.8111\n",
      "Epoch 22/25\n",
      "10320/10320 [==============================] - 10s 942us/step - loss: 0.1216 - accuracy: 0.8301 - val_loss: 0.1459 - val_accuracy: 0.7886\n",
      "Epoch 23/25\n",
      "10320/10320 [==============================] - 8s 783us/step - loss: 0.1232 - accuracy: 0.8297 - val_loss: 0.1375 - val_accuracy: 0.8097\n",
      "Epoch 24/25\n",
      "10320/10320 [==============================] - 10s 929us/step - loss: 0.1228 - accuracy: 0.8284 - val_loss: 0.1391 - val_accuracy: 0.8000\n",
      "Epoch 25/25\n",
      "10320/10320 [==============================] - 8s 780us/step - loss: 0.1213 - accuracy: 0.8323 - val_loss: 0.1568 - val_accuracy: 0.7797\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = ann_model.fit(x_train, y_train, epochs=25, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8444, Test acc: 0.7797\n",
      "ann: 0.5571510626076966\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = ann_model.evaluate(x_train, y_train, verbose=0)\n",
    "_, test_acc = ann_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Train acc: %.4f, Test acc: %.4f' % (train_acc, test_acc))\n",
    "\n",
    "ann_y_preds = ann_model.predict_classes(x_test)\n",
    "\n",
    "# Get score \n",
    "# f1_score(y_test, ann_y_preds)\n",
    "print(\"ann:\", f1_score(y_test, ann_y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
