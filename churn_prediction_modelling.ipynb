{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling data\n",
    "\n",
    "Lets select the best model among logistic regression, svm, random forest, gbm & neural network.\n",
    "\n",
    "Will be using 5 fold cross validation in the model training process and Grid search for the model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load feature engineered train, test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('data/train_features.csv')\n",
    "x_test = pd.read_csv('data/test_features.csv')\n",
    "\n",
    "y_train = pd.read_csv('data/train_labels.csv')\n",
    "y_test = pd.read_csv('data/test_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_acc = {}\n",
    "model_f1 = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to evaluate cross validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate cross validation results\n",
    "def print_results(results, model):\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('Acc: {} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))\n",
    "        \n",
    "    print('\\nBest Params: {},'.format(results.best_params_), 'Accuracy: {}'.format(results.best_score_))\n",
    "    # add to model_acc dict\n",
    "    model_acc[model] = str(round(results.best_score_,3))\n",
    "        \n",
    "# Function to get f1 score of the best model\n",
    "def best_model_f1_score(results, model):\n",
    "    y_pred = results.best_estimator_.predict(x_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    # add to model_f1 dict\n",
    "    model_f1[model] = round(f1,3)\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.717 (+/-0.12) for {'C': 0.001}\n",
      "Acc: 0.731 (+/-0.11) for {'C': 0.01}\n",
      "Acc: 0.748 (+/-0.106) for {'C': 0.1}\n",
      "Acc: 0.752 (+/-0.097) for {'C': 1}\n",
      "Acc: 0.752 (+/-0.096) for {'C': 10}\n",
      "Acc: 0.752 (+/-0.097) for {'C': 100}\n",
      "Acc: 0.752 (+/-0.097) for {'C': 1000}\n",
      "\n",
      "Best Params: {'C': 10}, Accuracy: 0.752422480620155\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "parameters = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "lr_cv = GridSearchCV(lr, parameters, cv=5)\n",
    "lr_cv.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# Find best model\n",
    "print_results(lr_cv,'lr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score gives an idea about both precision and recall. It is a better metric when there are imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score - lr: 0.45484581497797355\n"
     ]
    }
   ],
   "source": [
    "print(\"f1 score - lr:\", best_model_f1_score(lr_cv,'lr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write out pickled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/lr_model.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write out pickled model\n",
    "joblib.dump(lr_cv.best_estimator_, 'models/lr_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression model with the best hyperparameter combination has accuracy of 0.752 and a f1-score of 0.454.\n",
    "##### Let's evaluate other models as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.749 (+/-0.103) for {'C': 0.1, 'kernel': 'linear'}\n",
      "Acc: 0.77 (+/-0.124) for {'C': 0.1, 'kernel': 'rbf'}\n",
      "Acc: 0.751 (+/-0.098) for {'C': 1, 'kernel': 'linear'}\n",
      "Acc: 0.807 (+/-0.1) for {'C': 1, 'kernel': 'rbf'}\n",
      "Acc: 0.752 (+/-0.098) for {'C': 10, 'kernel': 'linear'}\n",
      "Acc: 0.822 (+/-0.086) for {'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Best Params: {'C': 10, 'kernel': 'rbf'}, Accuracy: 0.8220930232558139\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "parameters = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "svm_cv = GridSearchCV(svc, parameters, cv=5)\n",
    "svm_cv.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "print_results(svm_cv,'svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score - svm: 0.5703794369645043\n"
     ]
    }
   ],
   "source": [
    "print(\"f1 score - svm:\", best_model_f1_score(svm_cv,'svm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/svm_model.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write out pickled model\n",
    "joblib.dump(svm_cv.best_estimator_, 'models/svm_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.73 (+/-0.106) for {'max_depth': 2, 'n_estimators': 5}\n",
      "Acc: 0.764 (+/-0.097) for {'max_depth': 2, 'n_estimators': 50}\n",
      "Acc: 0.768 (+/-0.086) for {'max_depth': 2, 'n_estimators': 250}\n",
      "Acc: 0.772 (+/-0.085) for {'max_depth': 4, 'n_estimators': 5}\n",
      "Acc: 0.794 (+/-0.09) for {'max_depth': 4, 'n_estimators': 50}\n",
      "Acc: 0.8 (+/-0.094) for {'max_depth': 4, 'n_estimators': 250}\n",
      "Acc: 0.812 (+/-0.073) for {'max_depth': 8, 'n_estimators': 5}\n",
      "Acc: 0.824 (+/-0.073) for {'max_depth': 8, 'n_estimators': 50}\n",
      "Acc: 0.825 (+/-0.076) for {'max_depth': 8, 'n_estimators': 250}\n",
      "Acc: 0.816 (+/-0.083) for {'max_depth': 16, 'n_estimators': 5}\n",
      "Acc: 0.848 (+/-0.077) for {'max_depth': 16, 'n_estimators': 50}\n",
      "Acc: 0.852 (+/-0.077) for {'max_depth': 16, 'n_estimators': 250}\n",
      "Acc: 0.821 (+/-0.066) for {'max_depth': 32, 'n_estimators': 5}\n",
      "Acc: 0.845 (+/-0.082) for {'max_depth': 32, 'n_estimators': 50}\n",
      "Acc: 0.85 (+/-0.077) for {'max_depth': 32, 'n_estimators': 250}\n",
      "Acc: 0.818 (+/-0.071) for {'max_depth': None, 'n_estimators': 5}\n",
      "Acc: 0.848 (+/-0.086) for {'max_depth': None, 'n_estimators': 50}\n",
      "Acc: 0.852 (+/-0.082) for {'max_depth': None, 'n_estimators': 250}\n",
      "\n",
      "Best Params: {'max_depth': 16, 'n_estimators': 250}, Accuracy: 0.8516472868217054\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250],\n",
    "    'max_depth': [2, 4, 8, 16, 32, None]\n",
    "}\n",
    "\n",
    "rf_cv = GridSearchCV(rf, parameters, cv=5)\n",
    "rf_cv.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "print_results(rf_cv,'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score - rf: 0.5905256327060351\n"
     ]
    }
   ],
   "source": [
    "print(\"f1 score - rf:\", best_model_f1_score(rf_cv,'rf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The default value for max_depth is None, which means that each tree will expand until every leaf is pure. A pure leaf is one where all of the data on the leaf comes from the same class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/rf_model.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write out pickled model\n",
    "joblib.dump(rf_cv.best_estimator_, 'models/rf_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.68 (+/-0.094) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 5}\n",
      "Acc: 0.705 (+/-0.04) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 50}\n",
      "Acc: 0.748 (+/-0.076) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 250}\n",
      "Acc: 0.775 (+/-0.077) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 500}\n",
      "Acc: 0.748 (+/-0.087) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 5}\n",
      "Acc: 0.754 (+/-0.087) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "Acc: 0.807 (+/-0.061) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 250}\n",
      "Acc: 0.819 (+/-0.064) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "Acc: 0.777 (+/-0.075) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 5}\n",
      "Acc: 0.79 (+/-0.061) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50}\n",
      "Acc: 0.821 (+/-0.069) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 250}\n",
      "Acc: 0.831 (+/-0.071) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500}\n",
      "Acc: 0.803 (+/-0.073) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 5}\n",
      "Acc: 0.812 (+/-0.077) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50}\n",
      "Acc: 0.831 (+/-0.07) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 250}\n",
      "Acc: 0.845 (+/-0.076) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 500}\n",
      "Acc: 0.803 (+/-0.069) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 5}\n",
      "Acc: 0.817 (+/-0.071) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 50}\n",
      "Acc: 0.838 (+/-0.077) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 250}\n",
      "Acc: 0.853 (+/-0.076) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 500}\n",
      "Acc: 0.69 (+/-0.102) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 5}\n",
      "Acc: 0.778 (+/-0.078) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 50}\n",
      "Acc: 0.811 (+/-0.071) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 250}\n",
      "Acc: 0.814 (+/-0.07) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 500}\n",
      "Acc: 0.757 (+/-0.089) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 5}\n",
      "Acc: 0.819 (+/-0.066) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "Acc: 0.839 (+/-0.071) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 250}\n",
      "Acc: 0.841 (+/-0.066) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "Acc: 0.793 (+/-0.058) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 5}\n",
      "Acc: 0.833 (+/-0.068) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}\n",
      "Acc: 0.854 (+/-0.076) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 250}\n",
      "Acc: 0.861 (+/-0.073) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500}\n",
      "Acc: 0.809 (+/-0.078) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 5}\n",
      "Acc: 0.844 (+/-0.071) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50}\n",
      "Acc: 0.865 (+/-0.069) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 250}\n",
      "Acc: 0.869 (+/-0.069) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Acc: 0.814 (+/-0.073) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 5}\n",
      "Acc: 0.85 (+/-0.076) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 50}\n",
      "Acc: 0.87 (+/-0.072) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 250}\n",
      "Acc: 0.871 (+/-0.065) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 500}\n",
      "Acc: 0.773 (+/-0.067) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 5}\n",
      "Acc: 0.814 (+/-0.069) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 50}\n",
      "Acc: 0.815 (+/-0.076) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 250}\n",
      "Acc: 0.814 (+/-0.078) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 500}\n",
      "Acc: 0.808 (+/-0.07) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 5}\n",
      "Acc: 0.822 (+/-0.068) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 50}\n",
      "Acc: 0.825 (+/-0.061) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 250}\n",
      "Acc: 0.828 (+/-0.067) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 500}\n",
      "Acc: 0.817 (+/-0.07) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 5}\n",
      "Acc: 0.832 (+/-0.064) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 50}\n",
      "Acc: 0.844 (+/-0.064) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 250}\n",
      "Acc: 0.852 (+/-0.063) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 500}\n",
      "Acc: 0.821 (+/-0.067) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 5}\n",
      "Acc: 0.838 (+/-0.07) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 50}\n",
      "Acc: 0.863 (+/-0.065) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 250}\n",
      "Acc: 0.869 (+/-0.066) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Acc: 0.816 (+/-0.065) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 5}\n",
      "Acc: 0.849 (+/-0.068) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 50}\n",
      "Acc: 0.872 (+/-0.071) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 250}\n",
      "Acc: 0.868 (+/-0.089) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 500}\n",
      "\n",
      "Best Params: {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 250}, Accuracy: 0.8722868217054265\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250, 500],\n",
    "    'max_depth': [1, 3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "gbm_cv = GridSearchCV(gb, parameters, cv=5)\n",
    "gbm_cv.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "print_results(gbm_cv,'gbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score - gbm: 0.5643496214728148\n"
     ]
    }
   ],
   "source": [
    "print(\"f1 score - gbm:\", best_model_f1_score(gbm_cv,'gbm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/gbm_model.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write out pickled model\n",
    "joblib.dump(gbm_cv.best_estimator_, 'models/gbm_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              11264     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 292,225\n",
      "Trainable params: 292,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann_model = Sequential()\n",
    "\n",
    "ann_model.add(Dense(1024, input_dim = 10, activation = 'relu'))\n",
    "ann_model.add(Dropout(0.4))\n",
    "\n",
    "ann_model.add(Dense(256, activation = 'relu'))\n",
    "ann_model.add(Dropout(0.4))\n",
    "\n",
    "ann_model.add(Dense(64, activation = 'relu'))\n",
    "ann_model.add(Dropout(0.4))\n",
    "\n",
    "ann_model.add(Dense(32, activation = 'relu'))\n",
    "\n",
    "ann_model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "ann_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "ann_model.compile(loss='mse', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.1799 - accuracy: 0.7321 - val_loss: 0.1951 - val_accuracy: 0.7157\n",
      "Epoch 2/25\n",
      "323/323 [==============================] - 3s 8ms/step - loss: 0.1594 - accuracy: 0.7679 - val_loss: 0.1868 - val_accuracy: 0.7257\n",
      "Epoch 3/25\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.1475 - accuracy: 0.7878 - val_loss: 0.1371 - val_accuracy: 0.8057\n",
      "Epoch 4/25\n",
      "323/323 [==============================] - 3s 8ms/step - loss: 0.1438 - accuracy: 0.7952 - val_loss: 0.1533 - val_accuracy: 0.7846\n",
      "Epoch 5/25\n",
      "323/323 [==============================] - 3s 8ms/step - loss: 0.1393 - accuracy: 0.7984 - val_loss: 0.1345 - val_accuracy: 0.8174\n",
      "Epoch 6/25\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 0.1377 - accuracy: 0.8029 - val_loss: 0.1548 - val_accuracy: 0.7863\n",
      "Epoch 7/25\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.1343 - accuracy: 0.8104 - val_loss: 0.1658 - val_accuracy: 0.7634\n",
      "Epoch 8/25\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 0.1326 - accuracy: 0.8157 - val_loss: 0.1521 - val_accuracy: 0.7829\n",
      "Epoch 9/25\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.1310 - accuracy: 0.8160 - val_loss: 0.1476 - val_accuracy: 0.7923\n",
      "Epoch 10/25\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.1306 - accuracy: 0.8168 - val_loss: 0.1451 - val_accuracy: 0.7851\n",
      "Epoch 11/25\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 0.1296 - accuracy: 0.8163 - val_loss: 0.1443 - val_accuracy: 0.7860\n",
      "Epoch 12/25\n",
      "323/323 [==============================] - 4s 11ms/step - loss: 0.1282 - accuracy: 0.8192 - val_loss: 0.1397 - val_accuracy: 0.8043\n",
      "Epoch 13/25\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 0.1272 - accuracy: 0.8210 - val_loss: 0.1495 - val_accuracy: 0.7946\n",
      "Epoch 14/25\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 0.1270 - accuracy: 0.8250 - val_loss: 0.1457 - val_accuracy: 0.7911\n",
      "Epoch 15/25\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.1254 - accuracy: 0.8262 - val_loss: 0.1434 - val_accuracy: 0.7977\n",
      "Epoch 16/25\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.1258 - accuracy: 0.8259 - val_loss: 0.1389 - val_accuracy: 0.8077\n",
      "Epoch 17/25\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.1259 - accuracy: 0.8252 - val_loss: 0.1395 - val_accuracy: 0.8014\n",
      "Epoch 18/25\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.1257 - accuracy: 0.8233 - val_loss: 0.1458 - val_accuracy: 0.7969\n",
      "Epoch 19/25\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.1250 - accuracy: 0.8264 - val_loss: 0.1528 - val_accuracy: 0.7851\n",
      "Epoch 20/25\n",
      "323/323 [==============================] - 3s 8ms/step - loss: 0.1233 - accuracy: 0.8299 - val_loss: 0.1432 - val_accuracy: 0.8017\n",
      "Epoch 21/25\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.1232 - accuracy: 0.8282 - val_loss: 0.1379 - val_accuracy: 0.8046\n",
      "Epoch 22/25\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.1235 - accuracy: 0.8290 - val_loss: 0.1453 - val_accuracy: 0.8029\n",
      "Epoch 23/25\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.1238 - accuracy: 0.8276 - val_loss: 0.1379 - val_accuracy: 0.8091\n",
      "Epoch 24/25\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.1223 - accuracy: 0.8312 - val_loss: 0.1569 - val_accuracy: 0.7737\n",
      "Epoch 25/25\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.1223 - accuracy: 0.8288 - val_loss: 0.1458 - val_accuracy: 0.7937\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = ann_model.fit(x_train, y_train, epochs=25, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8437, Test acc: 0.7937\n",
      "ann: 0.5732860520094563\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = ann_model.evaluate(x_train, y_train, verbose=0)\n",
    "_, test_acc = ann_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Train acc: %.4f, Test acc: %.4f' % (train_acc, test_acc))\n",
    "\n",
    "# add to model_acc dict\n",
    "model_acc['ann'] = round(test_acc,3)\n",
    "\n",
    "ann_y_preds = ann_model.predict_classes(x_test)\n",
    "\n",
    "# Get f1 score\n",
    "f1_ann = f1_score(y_test, ann_y_preds)\n",
    "print(\"ann:\", f1_ann)\n",
    "\n",
    "# add to model_f1 dict\n",
    "model_f1['ann'] = round(f1_ann,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out keras model\n",
    "ann_model.save('models/ann_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.752</td>\n",
       "      <td>0.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.822</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbm</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ann</th>\n",
       "      <td>0.794</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Acc     F1\n",
       "lr   0.752  0.455\n",
       "svm  0.822   0.57\n",
       "rf   0.852  0.591\n",
       "gbm  0.872  0.564\n",
       "ann  0.794  0.573"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_f1_list = [model_acc, model_f1]\n",
    "\n",
    "df_eval = pd.DataFrame.from_records(acc_f1_list).T\n",
    "df_eval.rename(columns = {0:'Acc', 1:'F1'}, inplace = True)\n",
    "\n",
    "display(df_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Low F1 scores are seen in all models due to the imbalanced nature of the dataset.\n",
    " - Evaluation of Accuracy and F1 scores among all models suggests that Support Vector Machine, Random Forest & Gradient Boosted Models are the best performers.\n",
    " - Although GBM has the best accuracy it's low f1 score compared to others gives the edge to the ***Random Forest Model***."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
